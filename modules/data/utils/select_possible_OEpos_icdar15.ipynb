{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1f7d12e-b770-4879-b41c-4a51508ef911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# icdar17 dataset 중에서 \"Latin & codec에 정의된 문자\"인 데이터만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a8a00c7-1753-44ea-9b23-33d6bee17872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c216fdc-e570-4f2d-8195-0c059a1e7491",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_path = '/opt/ml/project/models/datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fa847ec-c50a-4012-bee0-746fa6ae893c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = datasets_path + '/train_gts_icdar15'\n",
    "file_names = sorted(os.listdir(file_path))\n",
    "image_path = datasets_path + '/train_images_icdar15'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a1b21c7-df83-49b8-a6f8-eeece4bf67f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_file_path = file_path + '_OEpos'\n",
    "new_image_path = image_path + '_OEpos'\n",
    "if not os.path.isdir(new_file_path):\n",
    "    os.makedirs(new_file_path)\n",
    "if not os.path.isdir(new_image_path):\n",
    "    os.makedirs(new_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb11386a-d617-43bc-b3c7-ec5e58556472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라틴 확장문자 변환  #Ĳ ĳ ĸ Œ œ ſ ŉ\n",
    "trans_char_dict = {\n",
    "    'À':'A', 'Á': 'A', 'Â': 'A', 'Ã': 'A', 'Ä': 'A', \n",
    "    'Ç':'C', 'È':'E', 'É':'E', 'Ê':'E', 'Ë':'E',\n",
    "    'Ì':'I', 'Î':'I', 'Ñ':'N', 'Ò':'O', 'Ô':'O', 'Ö':'O', 'Ù':'U', 'Ü':'U', \n",
    "    'à':'a', 'á':'a', 'â':'a', 'ä':'a', 'ç':'c', 'è':'e', 'é':'e', 'ê':'e', 'ì':'i', 'î':'i', 'ò':'o', 'ó':'o', 'ô':'o', 'ö':'o',\n",
    "    'ù':'u', 'ú':'u', 'û':'u', 'ü':'u',\n",
    "    'Ā':'A', 'ō':'o', 'Œ':'OE', 'œ':'oe', 'Š':'S','Ṡ':'S', 'Ÿ':'Y',\n",
    "    '、':',', '‘':'\\'', '《':'<', '》':'>','–':'-', '—':'-', '’':'\\'', '“':'\\\"', '”':'\\\"',\n",
    "    '²':'2', '×':'x', '™':'TM', '▪':'·', '●':'·', '・':'·', 'ـ':'_', '´':'\\''\n",
    "}\n",
    "# transTable = txt.maketrans(trans_char_dict)\n",
    "# txt = txt.translate(transTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6876d355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ`=;,./~!@#$%^&*()_+|:<>?°·£¥₩€-[]'\"{}\\\n"
     ]
    }
   ],
   "source": [
    "with open('/opt/ml/project/models/modules/utils/codec.txt', 'r') as f:\n",
    "    keys = f.readlines()[0]\n",
    "    print(keys)\n",
    "regular_char = re.compile(r\"[ 0-9a-zA-Z`=;,./~!@#$%^&*()_+|:<>?°·£¥₩€\\-\\[\\]\\'\\\"\\{\\}\\\\]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "712f3e63-da14-477c-a05e-d2911297a29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_possible_word(word) -> bool:\n",
    "    for char in word:\n",
    "        if not regular_char.match(char):\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9db4fa8-6ac9-487b-a016-834c2a3e1365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".ipynb_checkpoints\n",
      "pos img: 979, neg img : 21\n",
      "total word: 11886, pog word : 4468\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "count_pos_img, count_neg_img = 0, 0\n",
    "count_pos_word, count_total_word = 0, 0\n",
    "\n",
    "remain_latin_set = set([])\n",
    "\n",
    "for file_name in file_names:\n",
    "    src = os.path.join(file_path, file_name)\n",
    "    try:\n",
    "        with open(src, 'r', encoding='utf-8') as f:\n",
    "            new_texts = ''\n",
    "            lines = f.readlines()\n",
    "            OEpos_exist = False\n",
    "            for line in lines:\n",
    "\n",
    "                texts = line[:-1].split(',')\n",
    "                bbox = ','.join(texts[:8])\n",
    "                script = '' #texts[8]\n",
    "                word = ','.join(texts[8:])\n",
    "                count_total_word += 1\n",
    "\n",
    "                if word == '':                    # 빈 문자열 지우기\n",
    "                    # count_neg_word += 1\n",
    "                    continue\n",
    "                elif word == '###':\n",
    "                    script = 'null'\n",
    "                else:\n",
    "                    transTable = word.maketrans(trans_char_dict)\n",
    "                    word = word.translate(transTable)\n",
    "\n",
    "                    if check_possible_word(word):\n",
    "                        script = 'OE_pos'\n",
    "                        OEpos_exist = True\n",
    "                        count_pos_word+=1\n",
    "                    else:\n",
    "                        script = 'Latin'\n",
    "                        for char in word:\n",
    "                            if not check_possible_word(char):\n",
    "                                remain_latin_set.add(char)\n",
    "                        word = '###'\n",
    "                new_texts += bbox+','+script+','+word+'\\n'\n",
    "    except:\n",
    "        print(file_name)\n",
    "        continue\n",
    "    if OEpos_exist:\n",
    "        count_pos_img += 1\n",
    "        new_src = os.path.join(new_file_path, file_name)\n",
    "        with open(new_src,'w') as f:\n",
    "            f.write(new_texts)\n",
    "        image_name = 'img_' + file_name.split('_')[2].split('.')[0]+'.*'\n",
    "        image_name = glob.glob(image_path+'/'+image_name)[0].split('/')[-1]\n",
    "        image_src = os.path.join(image_path, image_name)\n",
    "        new_image_src = os.path.join(new_image_path, image_name)\n",
    "        shutil.copyfile(image_src, new_image_src)\n",
    "    # #     # print(image_src, new_image_src)\n",
    "    else:\n",
    "        count_neg_img += 1\n",
    "print('pos img: '+str(count_pos_img)+', neg img : '+str(count_neg_img))\n",
    "print('total word: '+str(count_total_word)+', pog word : '+str(count_pos_word))\n",
    "print(sorted(list(remain_latin_set)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightweight",
   "language": "python",
   "name": "lightweight"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
